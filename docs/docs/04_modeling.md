# 04 â€“ Modeling  

## ğŸ¯ Objetivo  
Construir, treinar e comparar modelos de Machine Learning capazes de prever:  
1. **Falha geral da mÃ¡quina** (`falha_maquina`, classificaÃ§Ã£o binÃ¡ria).  
2. **Tipos especÃ­ficos de falhas** (`FDF`, `FDC`, `FP`, `FTE`, `FA`, classificaÃ§Ã£o multirrÃ³tulo).  

O objetivo Ã© selecionar o modelo que atenda melhor aos critÃ©rios de negÃ³cio e tÃ©cnicos definidos no **Business Understanding**.  

---

## ğŸ“‚ Entrada  
- Dados preparados conforme descrito em [`03_data_preparation.md`](./03_data_preparation.md).  
- Conjuntos de treino e validaÃ§Ã£o salvos em `data/interim/` e `data/processed/`.  

---

## âš™ï¸ Modelos Testados  

### ğŸ”¹ Baseline  
- **RegressÃ£o LogÃ­stica (One-vs-Rest)**  
  - Justificativa: modelo simples e interpretÃ¡vel, Ãºtil como benchmark inicial.  

### ğŸ”¹ Ãrvores de DecisÃ£o / Ensembles  
- **Random Forest Classifier**  
  - Justificativa: robusto, lida bem com nÃ£o linearidade e variÃ¡veis correlacionadas.  
- **XGBoost / Gradient Boosting**  
  - Justificativa: alta performance em dados tabulares e competiÃ§Ãµes de ML.  

### ğŸ”¹ Outros modelos candidatos (opcional)  
- SVM, KNN, Redes Neurais â€” se houver tempo para exploraÃ§Ã£o.  

---

## ğŸ“ MÃ©tricas de AvaliaÃ§Ã£o  

- **AcurÃ¡cia** (para baseline, nÃ£o suficiente em dados desbalanceados).  
- **PrecisÃ£o, Recall, F1-score** (mÃ©tricas principais para avaliar falhas).  
- **ROC-AUC** (avalia separabilidade das classes).  
- **Hamming Loss / Subset Accuracy** (para multirrÃ³tulo).  

---

## ğŸ§¾ EstratÃ©gia  

- **Cross-validation** k-fold estratificada para `falha_maquina`.  
- DivisÃ£o treino/validaÃ§Ã£o estratificada para multirrÃ³tulo.  
- Balanceamento aplicado **apenas no treino** (ex.: SMOTE).  
- ComparaÃ§Ã£o justa entre modelos com os mesmos splits.  

---

## ğŸ§ª Resultados Preliminares  

| Modelo            | Target            | F1-score | Recall | Precision | ROC-AUC |
|-------------------|------------------|----------|--------|-----------|---------|
| Logistic Regression | falha_maquina   | 0.xx     | 0.xx   | 0.xx      | 0.xx    |
| Random Forest       | falha_maquina   | 0.xx     | 0.xx   | 0.xx      | 0.xx    |
| XGBoost             | falha_maquina   | 0.xx     | 0.xx   | 0.xx      | 0.xx    |
| Random Forest       | MultirrÃ³tulo    | 0.xx     | 0.xx   | 0.xx      | â€“       |
| XGBoost             | MultirrÃ³tulo    | 0.xx     | 0.xx   | 0.xx      | â€“       |

*(valores serÃ£o preenchidos apÃ³s execuÃ§Ã£o dos notebooks)*  

---

## ğŸ” Explicabilidade (XAI)  

- **Feature Importance (Ã¡rvores)**: torque, temperatura_processo e desgaste_da_ferramenta aparecem como variÃ¡veis mais relevantes.  
- **SHAP Values**: permitem entender impacto de variÃ¡veis em prediÃ§Ãµes individuais (ex.: desgaste alto â†’ probabilidade maior de FDF).  
- **LIME (opcional)**: explicaÃ§Ãµes locais para casos de falha/nÃ£o falha.  

---

## âœ… SeleÃ§Ã£o do Modelo Final  

CritÃ©rios para escolha:  
- Melhor equilÃ­brio entre **Recall e F1-score** (evitar falsos negativos em falhas).  
- Estabilidade e interpretabilidade para stakeholders de manutenÃ§Ã£o.  
- Performance consistente em validaÃ§Ã£o cruzada.  

> Modelo selecionado: **[preencher apÃ³s anÃ¡lise]**  

---

## ğŸ“‚ SaÃ­das  

- Pipeline do modelo salvo em `data/processed/model_final.joblib`.  
- Notebook `notebooks/modeling.ipynb` documenta os testes e comparaÃ§Ãµes.  
- Resultados consolidados prontos para fase de [`05_evaluation.md`](./05_evaluation.md).  
