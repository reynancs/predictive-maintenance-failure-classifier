{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "üìí `2.0-rc-data-preparation.ipynb`\n",
    "\n",
    "**Objetivo:** Transformar os dados brutos em um formato para uso em an√°lise explorat√≥ria e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "# Utils\n",
    "from src._utils import detect_outliers_iqr, plot_outliers, handle_outliers, analyze_outliers, plot_distribution_and_boxplot\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura o matplotlib para mostrar gr√°ficos inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Setup para mostrar todas as colunas do dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Limpeza dos Dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Remove colunas desnecess√°rias e renomeia as colunas e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados\n",
    "df = pd.read_csv(\"../data/raw/bootcamp_train.csv\")\n",
    "print( \"N¬∞ de linhas e colunas: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleta as colunas que n√£o s√£o necess√°rias\n",
    "df.drop(columns=['id', 'id_produto'], inplace=True)\n",
    "\n",
    "# Renomeia as colunas\n",
    "cols_to_rename = {\n",
    "    'tipo': 'tipo',\n",
    "    'temperatura_ar': 'temperatura_ar',\n",
    "    'temperatura_processo': 'temperatura_processo',\n",
    "    'umidade_relativa': 'umidade_relativa',\n",
    "    'velocidade_rotacional': 'velocidade_rotacional',\n",
    "    'torque': 'torque',\n",
    "    'desgaste_da_ferramenta': 'desgaste_da_ferramenta',\n",
    "    'falha_maquina': 'falha_maquina',\n",
    "    'FTE (Falha Tensao Excessiva)': 'Tensao Excessiva(FTE)',\n",
    "    'FDC (Falha Dissipacao Calor)': 'Dissipacao de Calor(FDC)',\n",
    "    'FP (Falha Potencia)': 'Falha de Potencia(FP)',\n",
    "    'FDF (Falha Desgaste Ferramenta)': 'Desgaste da Ferramenta(FDF)',\n",
    "    'FA (Falha Aleatoria)': 'Falha Aleatoria(FA)'\n",
    "}\n",
    "\n",
    "# Renomeia as colunas\n",
    "df.rename(columns=cols_to_rename, inplace=True)\n",
    "\n",
    "\n",
    "### Renomeia as classes da coluna `tipo` para facilitar a interpreta√ß√£o\n",
    "dict_type = {\n",
    "    'L': 'Baixa', \n",
    "    'M': 'Media', \n",
    "    'H': 'Alta'\n",
    "    }\n",
    "# Aplica o mapeamento\n",
    "df['tipo'] = df['tipo'].map(dict_type)\n",
    "\n",
    "\n",
    "# Visualiza as 5 primeiras linhas\n",
    "print( \"N¬∞ de linhas e colunas: \", df.shape)\n",
    "print(\"Visualiza as 5 primeiras linhas:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### b) Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dados Nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando Valores Nulos\n",
    "# Preenchimento de valores ausentes com a mediana ( menos sensivel aos outliers)\n",
    "\n",
    "num_cols_to_inspect = [\n",
    "    'temperatura_ar', \n",
    "    'temperatura_processo', \n",
    "    'umidade_relativa', \n",
    "    'velocidade_rotacional', \n",
    "    'torque', \n",
    "    'desgaste_da_ferramenta'\n",
    "    ]\n",
    "\n",
    "for col in num_cols_to_inspect:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "print(\"Valores Nulos tratados com a mediana: \\n\", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Inconsist√™ncia nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dados Inconsistentes\n",
    "print(\"Descri√ß√£o dos dados num√©ricos: \\n\", df.describe())\n",
    "print(\"-\"*50)\n",
    "\n",
    "for col in num_cols_to_inspect:\n",
    "    print(df.loc[df[col] < 0, col].value_counts())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Trata Inconsist√™ncias com a mediana\n",
    "for col in num_cols_to_inspect:\n",
    "    df.loc[df[col] < 0, col] = df[col].median()\n",
    "\n",
    "print(\"Inconsist√™ncias tratadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dados de classes com inconsist√™ncias\n",
    "cols_to_inspect = [\n",
    "    'falha_maquina', \n",
    "    'Desgaste da Ferramenta(FDF)', \n",
    "    'Dissipacao de Calor(FDC)', \n",
    "    'Falha de Potencia(FP)', \n",
    "    'Tensao Excessiva(FTE)', \n",
    "    'Falha Aleatoria(FA)'\n",
    "    ]\n",
    "\n",
    "# Verifica valores √∫nicos em todas as colunas\n",
    "for col in cols_to_inspect:\n",
    "    print(f\"Coluna: {col}\")\n",
    "    print(f\"Valores √∫nicos: {df[col].unique()}\")\n",
    "    print(f\"Quantidade de valores √∫nicos: {df[col].nunique()}\")\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de mapeamento para padronizar valores bin√°rios\n",
    "map_classes = {\n",
    "    # Valores que representam \"0\" (n√£o/falso)\n",
    "    'n√£o': '0',\n",
    "    'N√£o': '0',\n",
    "    'N': '0',\n",
    "    'False': '0',\n",
    "    'false': '0',\n",
    "    'nao': '0',\n",
    "    '-': '0',\n",
    "    # Valores que representam \"1\" (sim/verdadeiro)\n",
    "    'sim': '1',\n",
    "    'Sim': '1',\n",
    "    'y': '1',\n",
    "    'True': '1',\n",
    "    'true': '1'\n",
    "}\n",
    "\n",
    "# Lista de colunas para aplicar a transforma√ß√£o\n",
    "cols_to_transform = [\n",
    "    'falha_maquina',\n",
    "    'Desgaste da Ferramenta(FDF)',\n",
    "    'Dissipacao de Calor(FDC)',\n",
    "    'Falha de Potencia(FP)',\n",
    "    'Tensao Excessiva(FTE)',\n",
    "    'Falha Aleatoria(FA)'\n",
    "]\n",
    "\n",
    "# Aplica a transforma√ß√£o em cada coluna\n",
    "for col in cols_to_transform:\n",
    "    df[col] = df[col].astype(str)\n",
    "    # Aplica o mapeamento\n",
    "    df[col] = df[col].map(lambda x: map_classes.get(x, x))\n",
    "    # Converte a coluna para tipo num√©rico\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# Verifica os valores √∫nicos ap√≥s a transforma√ß√£o\n",
    "print(\"Verifica√ß√£o ap√≥s a transforma√ß√£o:\")\n",
    "print(\"-\" * 50)\n",
    "for col in cols_to_transform:\n",
    "    print(f\"Coluna: {col}\")\n",
    "    print(f\"Valores √∫nicos: {df[col].unique()}\")\n",
    "    print(f\"Quantidade: {df[col].nunique()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de mapeamento para o tipo de falha com os novos nomes das colunas\n",
    "dict_tipo_falha = {\n",
    "    'Desgaste da Ferramenta(FDF)': 'Desgaste da Ferramenta(FDF)', \n",
    "    'Dissipacao de Calor(FDC)': 'Dissipacao de Calor(FDC)', \n",
    "    'Falha de Potencia(FP)': 'Falha de Potencia(FP)', \n",
    "    'Tensao Excessiva(FTE)': 'Tensao Excessiva(FTE)', \n",
    "    'Falha Aleatoria(FA)': 'Falha Aleatoria(FA)'\n",
    "}\n",
    "\n",
    "# Fun√ß√£o para determinar o tipo de falha usando os novos nomes\n",
    "def get_tipo_falha(row):\n",
    "    # Verifica cada coluna de falha\n",
    "    for col in dict_tipo_falha.keys():\n",
    "        try:\n",
    "            if row[col] == 1:\n",
    "                return dict_tipo_falha[col]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return \"Sem falhas\"\n",
    "\n",
    "# Criar a nova coluna tipo_falha\n",
    "df['tipo_falha'] = df.apply(get_tipo_falha, axis=1)\n",
    "\n",
    "# Verificar a distribui√ß√£o dos tipos de falha\n",
    "print(\"\\nDistribui√ß√£o dos tipos de falha:\")\n",
    "print(df['tipo_falha'].value_counts())\n",
    "\n",
    "\n",
    "# Verificando se h√° inconsist√™ncias na classifica√ß√£o\n",
    "#df[(df['falha_maquina'] == 1) & (df['tipo_falha'] == 'Sem falhas')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Dados Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dados Duplicados removidos: \", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) An√°lise de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise da distribui√ß√£o das vari√°veis num√©ricas\n",
    "print(\"An√°lise da distribui√ß√£o das vari√°veis num√©ricas:\")\n",
    "\n",
    "# Declarando as colunas alvo\n",
    "target_cols = ['falha_maquina', 'Falha Aleatoria(FA)', 'Falha de Potencia(FP)', 'Tensao Excessiva(FTE)', 'Dissipacao de Calor(FDC)', 'Desgaste da Ferramenta(FDF)']\n",
    "\n",
    "# Seleciona as colunas num√©ricas\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.drop(target_cols).tolist()\n",
    "\n",
    "# Plotar a distribui√ß√£o e o boxplot das vari√°veis num√©ricas\n",
    "plot_distribution_and_boxplot(df_clean, numeric_cols)\n",
    "\n",
    "# Mostrar estat√≠sticas descritivas\n",
    "print(\"\\nEstat√≠sticas descritivas das vari√°veis num√©ricas:\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Salvar o gr√°fico com melhor qualidade\n",
    "plt.savefig('../reports/figures/2_data_preparation_outliers', \n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m√°scara acumulada de \"√© outlier em QUALQUER coluna\"\n",
    "any_outlier = pd.Series(False, index=df.index)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mask, stats = detect_outliers_iqr(df[col], col)\n",
    "    any_outlier |= mask  # acumula outliers\n",
    "\n",
    "# remover linhas que s√£o outlier em qualquer coluna\n",
    "df_clean = df.loc[~any_outlier].copy()\n",
    "\n",
    "print(f\"Linhas originais: {len(df)}\")\n",
    "print(f\"Linhas removidas (outliers): {any_outlier.sum()}\")\n",
    "print(f\"Linhas ap√≥s limpeza: {len(df_clean)}\")\n",
    "\n",
    "# An√°lise resumida\n",
    "outlier_analysis = analyze_outliers(df_clean, numeric_cols) \n",
    "print(outlier_analysis.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remo√ß√£o da vari√°vel de umidade relativa\n",
    "\n",
    "NOta: A vari√°vel `umidade_relativa` n√£o possui varia√ß√£o, possui pouca informa√ß√£o sobre os dados de falha, sendo assim, **esta vari√°vel ser√° removida dos estudos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['umidade_relativa'], inplace=True)\n",
    "\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reordena as colunas e reseta index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reordena as colunas\n",
    "cols_to_reorder = [\n",
    "    'tipo', \n",
    "    'temperatura_ar', \n",
    "    'temperatura_processo', \n",
    "    'velocidade_rotacional', \n",
    "    'torque', \n",
    "    'desgaste_da_ferramenta', \n",
    "    'falha_maquina', \n",
    "    'tipo_falha',\n",
    "    'Desgaste da Ferramenta(FDF)',\n",
    "    'Dissipacao de Calor(FDC)',\n",
    "    'Falha de Potencia(FP)',  \n",
    "    'Tensao Excessiva(FTE)',\n",
    "    'Falha Aleatoria(FA)',\n",
    "    ]\n",
    "\n",
    "# Reordena as colunas\n",
    "df_clean = df_clean[cols_to_reorder]\n",
    "\n",
    "# Salva o dataset tratado\n",
    "path_to_save = \"../data/processed/data_cleaned.csv\"\n",
    "df_clean.to_csv(path_to_save, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiza os Dados com Pandas Profile Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados p√≥s tratamento com Pandas Profiling\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "FILE_PATH = \"../reports/profile-reports/data_cleaned.html\"\n",
    "\n",
    "profile = ProfileReport(\n",
    "    df_clean,\n",
    "    title=\"Profiling Report - Dados Tratados\"\n",
    ")\n",
    "\n",
    "# Salva HTML est√°tico\n",
    "profile.to_file(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pr√© Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# Configura√ß√£o\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribui√ß√£o das classes (dataset completo):\n",
      "falha_maquina\n",
      "0    98.45%\n",
      "1     1.55%\n",
      "Name: proporcao, dtype: object\n",
      "Alvo (y): falha_maquina ‚Äî tipo: int64\n",
      "\n",
      "Atributos Num√©ricos (X): ['temperatura_ar', 'temperatura_processo', 'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']\n",
      "\n",
      "Atributos Categ√≥ricos (X): ['tipo']\n",
      "\n",
      "Distribui√ß√£o das classes (dataset completo):\n",
      "falha_maquina\n",
      "0    98.45%\n",
      "1     1.55%\n",
      "Name: proporcao, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset tratado\n",
    "df = pd.read_csv('../data/processed/data_cleaned.csv')\n",
    "\n",
    "# Colunas a excluir de X para evitar vazamento de informa√ß√£o\n",
    "cols_excluir = [\n",
    "    'tipo_falha',                     \n",
    "    'falha_maquina',                   \n",
    "    'Falha de Potencia(FP)', \n",
    "    'Dissipacao de Calor(FDC)', \n",
    "    'Tensao Excessiva(FTE)', \n",
    "    'Desgaste da Ferramenta(FDF)', \n",
    "    'Falha Aleatoria(FA)'\n",
    "]\n",
    "\n",
    "# Seleciona os atributos (X) e a vari√°vel alvo (y)\n",
    "X = df.drop(columns=[c for c in cols_excluir if c in df.columns]).copy()\n",
    "y = df['falha_maquina'].copy()\n",
    "\n",
    "\n",
    "# Identifica e seleciona os atributos num√©ricos e categ√≥ricos\n",
    "numeric_cols   = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categoric_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Divis√£o treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Monta transformadores apenas se houver colunas do tipo\n",
    "transformers = []\n",
    "if numeric_cols:\n",
    "    transformers.append(('num', StandardScaler(), numeric_cols))\n",
    "if categoric_cols:\n",
    "    transformers.append(('cat', OneHotEncoder(handle_unknown='ignore'), categoric_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder='drop'  # descarta qualquer coluna n√£o transformada (por seguran√ßa)\n",
    ")\n",
    "\n",
    "\n",
    "# Infos adicionais\n",
    "print(f\"Alvo (y): {y.name} ‚Äî tipo: {y.dtype}\")\n",
    "print(\"\\nAtributos Num√©ricos (X):\", numeric_cols if numeric_cols else \"‚Äî (nenhum)\")\n",
    "print(\"\\nAtributos Categ√≥ricos (X):\", categoric_cols if categoric_cols else \"‚Äî (nenhum)\")\n",
    "\n",
    "print(\"\\nDistribui√ß√£o das classes (dataset completo):\")\n",
    "print(y.value_counts(normalize=True).rename('proporcao').mul(100).round(2).astype(str) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artefatos salvos em ../models/artifacts e splits em ../data/interim.\n"
     ]
    }
   ],
   "source": [
    "# Persist√™ncia dos dados tratados\n",
    "os.makedirs('../models/artifacts', exist_ok=True)\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "os.makedirs('../data/interim', exist_ok=True)\n",
    "\n",
    "# Salvar os splits para manter os dados tratados\n",
    "X_train.to_csv('../data/interim/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/interim/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/interim/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/interim/y_test.csv', index=False)\n",
    "\n",
    "# Salvar ‚Äúespecifica√ß√£o‚Äù do pr√©-processamento (listas de colunas + objeto definido/sem ajuste)\n",
    "dump({\n",
    "    \"numeric_cols\": numeric_cols,\n",
    "    \"categorical_cols\": categoric_cols,\n",
    "    \"preprocessor\": preprocessor,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"target_name\": \"tipo_falha\",\n",
    "    \"target_vars_all\": cols_excluir,\n",
    "    # utilidades para refer√™ncia futura\n",
    "    \"classes_\": sorted(y.unique().tolist()),\n",
    "    \"class_distribution_full\": y.value_counts(normalize=True).to_dict()\n",
    "}, \"../models/artifacts/preprocessing_spec.joblib\")\n",
    "\n",
    "print(\"\\nArtefatos salvos em ../models/artifacts e splits em ../data/interim.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
